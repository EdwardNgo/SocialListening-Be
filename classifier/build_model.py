from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
from pyvi import ViTokenizer, ViPosTagger
import re
import pandas as pd
import string
import codecs
import tqdm
from fasttext import train_supervised, load_model
import os


# Tá»« Ä‘iá»ƒn tÃ­ch cá»±c, tiÃªu cá»±c, phá»§ Ä‘á»‹nh
path_neg = "../classifier/sentiment_dicts/neg.txt"
path_pos = "../classifier/sentiment_dicts/pos.txt"
path_not = "../classifier/sentiment_dicts/not.txt"
stopwords_path = "../classifier/sentiment_dicts/stopwords.txt"


def load_list(filepath):
    with codecs.open(filepath, "r", encoding="UTF-8") as f:
        data_list = f.readlines()
    word_list = [n.replace("\n", "") for n in data_list]
    return word_list


neg_list = load_list(path_neg)
pos_list = load_list(path_pos)
not_list = load_list(path_not)
stw_list = load_list(stopwords_path)

# with codecs.open(path_neg, "r", encoding="UTF-8") as f:
#     neg = f.readlines()
# neg_list = [n.replace("\n", "") for n in neg]

# with codecs.open(path_pos, "r", encoding="UTF-8") as f:
#     pos = f.readlines()
# pos_list = [n.replace("\n", "") for n in pos]
# with codecs.open(path_not, "r", encoding="UTF-8") as f:
#     not_ = f.readlines()
# not_list = [n.replace("\n", "") for n in not_]

# with codecs.open(stopwords_path, "r", encoding="UTF-8") as f:
#     stw = f.readlines()
# stw_list = [n.replace("\n", "") for n in stw]


def preprocessing(text):
    # Remove cÃ¡c kÃ½ tá»± kÃ©o dÃ i: vd: Ä‘áº¹ppppppp
    text = re.sub(
        r"([A-Z])\1+", lambda m: m.group(1).upper(), text, flags=re.IGNORECASE
    )
    text = re.sub(
        r"(https?:\/\/)?([\da-z\.-]+)\.([a-z\.]{2,6})([\/\w \.-]*)", " ", text)
    # Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng
    text = text.lower()

    # Chuáº©n hÃ³a tiáº¿ng Viá»‡t, xá»­ lÃ½ emoj, chuáº©n hÃ³a tiáº¿ng Anh, thuáº­t ngá»¯
    replace_list = {
        "Ã²a": "oÃ ",
        "Ã³a": "oÃ¡",
        "á»a": "oáº£",
        "Ãµa": "oÃ£",
        "á»a": "oáº¡",
        "Ã²e": "oÃ¨",
        "Ã³e": "oÃ©",
        "á»e": "oáº»",
        "Ãµe": "oáº½",
        "á»e": "oáº¹",
        "Ã¹y": "uá»³",
        "Ãºy": "uÃ½",
        "á»§y": "uá»·",
        "Å©y": "uá»¹",
        "á»¥y": "uá»µ",
        "uáº£": "á»§a",
        "aÌ‰": "áº£",
        "Ã´Ì": "á»‘",
        "uÂ´": "á»‘",
        "Ã´Ìƒ": "á»—",
        "Ã´Ì€": "á»“",
        "Ã´Ì‰": "á»•",
        "Ã¢Ì": "áº¥",
        "Ã¢Ìƒ": "áº«",
        "Ã¢Ì‰": "áº©",
        "Ã¢Ì€": "áº§",
        "oÌ‰": "á»",
        "ÃªÌ€": "á»",
        "ÃªÌƒ": "á»…",
        "ÄƒÌ": "áº¯",
        "uÌ‰": "á»§",
        "ÃªÌ": "áº¿",
        "Æ¡Ì‰": "á»Ÿ",
        "iÌ‰": "á»‰",
        "eÌ‰": "áº»",
        "Ã k": " Ã  ",
        "aË‹": "Ã ",
        "iË‹": "Ã¬",
        "ÄƒÂ´": "áº¯",
        "Æ°Ì‰": "á»­",
        "eËœ": "áº½",
        "yËœ": "á»¹",
        "aÂ´": "Ã¡",
        # Quy cÃ¡c icon vá» 2 loáº¡i emoj: TÃ­ch cá»±c hoáº·c tiÃªu cá»±c
        "ğŸ‘¹": "negative",
        "ğŸ‘»": "positive",
        "ğŸ’ƒ": "positive",
        "ğŸ¤™": " positive ",
        "ğŸ‘": " positive ",
        "ğŸ’„": "positive",
        "ğŸ’": "positive",
        "ğŸ’©": "positive",
        "ğŸ˜•": "negative",
        "ğŸ˜±": "negative",
        "ğŸ˜¸": "positive",
        "ğŸ˜¾": "negative",
        "ğŸš«": "negative",
        "ğŸ¤¬": "negative",
        "ğŸ§š": "positive",
        "ğŸ§¡": "positive",
        "ğŸ¶": " positive ",
        "ğŸ‘": " negative ",
        "ğŸ˜£": " negative ",
        "âœ¨": " positive ",
        "â£": " positive ",
        "â˜€": " positive ",
        "â™¥": " positive ",
        "ğŸ¤©": " positive ",
        "like": " positive ",
        "ğŸ’Œ": " positive ",
        "ğŸ¤£": " positive ",
        "ğŸ–¤": " positive ",
        "ğŸ¤¤": " positive ",
        ":(": " negative ",
        "ğŸ˜¢": " negative ",
        "â¤": " positive ",
        "ğŸ˜": " positive ",
        "ğŸ˜˜": " positive ",
        "ğŸ˜ª": " negative ",
        "ğŸ˜Š": " positive ",
        "?": " ? ",
        "ğŸ˜": " positive ",
        "ğŸ’–": " positive ",
        "ğŸ˜Ÿ": " negative ",
        "ğŸ˜­": " negative ",
        "ğŸ’¯": " positive ",
        "ğŸ’—": " positive ",
        "â™¡": " positive ",
        "ğŸ’œ": " positive ",
        "ğŸ¤—": " positive ",
        "^^": " positive ",
        "ğŸ˜¨": " negative ",
        "â˜º": " positive ",
        "ğŸ’‹": " positive ",
        "ğŸ‘Œ": " positive ",
        "ğŸ˜–": " negative ",
        "ğŸ˜€": " positive ",
        ":((": " negative ",
        "ğŸ˜¡": " negative ",
        "ğŸ˜ ": " negative ",
        "ğŸ˜’": " negative ",
        "ğŸ™‚": " positive ",
        "ğŸ˜": " negative ",
        "ğŸ˜": " positive ",
        "ğŸ˜„": " positive ",
        "ğŸ˜™": " positive ",
        "ğŸ˜¤": " negative ",
        "ğŸ˜": " positive ",
        "ğŸ˜†": " positive ",
        "ğŸ’š": " positive ",
        "âœŒ": " positive ",
        "ğŸ’•": " positive ",
        "ğŸ˜": " negative ",
        "ğŸ˜“": " negative ",
        "ï¸ğŸ†—ï¸": " positive ",
        "ğŸ˜‰": " positive ",
        "ğŸ˜‚": " positive ",
        ":v": "  positive ",
        "=))": "  positive ",
        "ğŸ˜‹": " positive ",
        "ğŸ’“": " positive ",
        "ğŸ˜": " negative ",
        ":3": " positive ",
        "ğŸ˜«": " negative ",
        "ğŸ˜¥": " negative ",
        "ğŸ˜ƒ": " positive ",
        "ğŸ˜¬": " ğŸ˜¬ ",
        "ğŸ˜Œ": " ğŸ˜Œ ",
        "ğŸ’›": " positive ",
        "ğŸ¤": " positive ",
        "ğŸˆ": " positive ",
        "ğŸ˜—": " positive ",
        "ğŸ¤”": " negative ",
        "ğŸ˜‘": " negative ",
        "ğŸ”¥": " negative ",
        "ğŸ™": " negative ",
        "ğŸ†—": " positive ",
        "ğŸ˜»": " positive ",
        "ğŸ’™": " positive ",
        "ğŸ’Ÿ": " positive ",
        "ğŸ˜š": " positive ",
        "âŒ": " negative ",
        "ğŸ‘": " positive ",
        ";)": " positive ",
        "<3": " positive ",
        "ğŸŒ": " positive ",
        "ğŸŒ·": " positive ",
        "ğŸŒ¸": " positive ",
        "ğŸŒº": " positive ",
        "ğŸŒ¼": " positive ",
        "ğŸ“": " positive ",
        "ğŸ…": " positive ",
        "ğŸ¾": " positive ",
        "ğŸ‘‰": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’¥": " positive ",
        "ğŸ’ª": " positive ",
        "ğŸ’°": " positive ",
        "ğŸ˜‡": " positive ",
        "ğŸ˜›": " positive ",
        "ğŸ˜œ": " positive ",
        "ğŸ™ƒ": " positive ",
        "ğŸ¤‘": " positive ",
        "ğŸ¤ª": " positive ",
        "â˜¹": " negative ",
        "ğŸ’€": " negative ",
        "ğŸ˜”": " negative ",
        "ğŸ˜§": " negative ",
        "ğŸ˜©": " negative ",
        "ğŸ˜°": " negative ",
        "ğŸ˜³": " negative ",
        "ğŸ˜µ": " negative ",
        "ğŸ˜¶": " negative ",
        "ğŸ™": " negative ",
        # Chuáº©n hÃ³a 1 sá»‘ sentiment words/English words
        ":))": "  positive ",
        ":)": " positive ",
        "Ã´ kÃªi": " ok ",
        "okie": " ok ",
        " o kÃª ": " ok ",
        "okey": " ok ",
        "Ã´kÃª": " ok ",
        "oki": " ok ",
        " oke ": " ok ",
        " okay": " ok ",
        "okÃª": " ok ",
        " tks ": " cÃ¡m Æ¡n ",
        "thks": " cÃ¡m Æ¡n ",
        "thanks": " cÃ¡m Æ¡n ",
        "ths": " cÃ¡m Æ¡n ",
        "thank": " cÃ¡m Æ¡n ",
        "â­": "star ",
        "*": "star ",
        "ğŸŒŸ": "star ",
        "ğŸ‰": " positive ",
        "kg ": " khÃ´ng ",
        "not": " khÃ´ng ",
        " kg ": " khÃ´ng ",
        '"k ': " khÃ´ng ",
        " kh ": " khÃ´ng ",
        "kÃ´": " khÃ´ng ",
        "hok": " khÃ´ng ",
        " kp ": " khÃ´ng pháº£i ",
        " kÃ´ ": " khÃ´ng ",
        '"ko ': " khÃ´ng ",
        " ko ": " khÃ´ng ",
        " k ": " khÃ´ng ",
        "khong": " khÃ´ng ",
        " hok ": " khÃ´ng ",
        "he he": " positive ",
        "hehe": " positive ",
        "hihi": " positive ",
        "haha": " positive ",
        "hjhj": " positive ",
        " lol ": " negative ",
        " cc ": " negative ",
        "cute": " dá»… thÆ°Æ¡ng ",
        "huhu": " negative ",
        " vs ": " vá»›i ",
        "wa": " quÃ¡ ",
        "wÃ¡": " quÃ¡",
        "j": " gÃ¬ ",
        "â€œ": " ",
        " sz ": " cá»¡ ",
        "size": " cá»¡ ",
        " Ä‘x ": " Ä‘Æ°á»£c ",
        "dk": " Ä‘Æ°á»£c ",
        "dc": " Ä‘Æ°á»£c ",
        "Ä‘k": " Ä‘Æ°á»£c ",
        "Ä‘c": " Ä‘Æ°á»£c ",
        "authentic": " chuáº©n chÃ­nh hÃ£ng ",
        " aut ": " chuáº©n chÃ­nh hÃ£ng ",
        " auth ": " chuáº©n chÃ­nh hÃ£ng ",
        "thick": " positive ",
        "store": " cá»­a hÃ ng ",
        "shop": " cá»­a hÃ ng ",
        "sp": " sáº£n pháº©m ",
        "gud": " tá»‘t ",
        "god": " tá»‘t ",
        "wel done": " tá»‘t ",
        "good": " tá»‘t ",
        "gÃºt": " tá»‘t ",
        "sáº¥u": " xáº¥u ",
        "gut": " tá»‘t ",
        " tot ": " tá»‘t ",
        " nice ": " tá»‘t ",
        "perfect": "ráº¥t tá»‘t",
        "bt": " bÃ¬nh thÆ°á»ng ",
        "time": " thá»i gian ",
        "qÃ¡": " quÃ¡ ",
        " ship ": " giao hÃ ng ",
        " m ": " mÃ¬nh ",
        " mik ": " mÃ¬nh ",
        "ÃªÌ‰": "á»ƒ",
        "product": "sáº£n pháº©m",
        "quality": "cháº¥t lÆ°á»£ng",
        "chat": " cháº¥t ",
        "excelent": "hoÃ n háº£o",
        "bad": "tá»‡",
        "fresh": " tÆ°Æ¡i ",
        "sad": " tá»‡ ",
        "date": " háº¡n sá»­ dá»¥ng ",
        "hsd": " háº¡n sá»­ dá»¥ng ",
        "quickly": " nhanh ",
        "quick": " nhanh ",
        "fast": " nhanh ",
        "delivery": " giao hÃ ng ",
        " sÃ­p ": " giao hÃ ng ",
        "beautiful": " Ä‘áº¹p tuyá»‡t vá»i ",
        " tl ": " tráº£ lá»i ",
        " r ": " rá»“i ",
        " shopE ": " cá»­a hÃ ng ",
        " order ": " Ä‘áº·t hÃ ng ",
        "cháº¥t lg": " cháº¥t lÆ°á»£ng ",
        " sd ": " sá»­ dá»¥ng ",
        " dt ": " Ä‘iá»‡n thoáº¡i ",
        " nt ": " nháº¯n tin ",
        " tl ": " tráº£ lá»i ",
        " sÃ i ": " xÃ i ",
        "bjo": " bao giá» ",
        "thik": " thÃ­ch ",
        " sop ": " cá»­a hÃ ng ",
        " fb ": " facebook ",
        " face ": " facebook ",
        " very ": " ráº¥t ",
        "quáº£ ng ": " quáº£ng  ",
        "dep": " Ä‘áº¹p ",
        " xau ": " xáº¥u ",
        "delicious": " ngon ",
        "hÃ g": " hÃ ng ",
        "qá»§a": " quáº£ ",
        "iu": " yÃªu ",
        "fake": " giáº£ máº¡o ",
        "trl": "tráº£ lá»i",
        "><": " positive ",
        " por ": " tá»‡ ",
        " poor ": " tá»‡ ",
        "ib": " nháº¯n tin ",
        "rep": " tráº£ lá»i ",
        "fback": " feedback ",
        "fedback": " feedback ",
        # dÆ°á»›i 3* quy vá» 1*, trÃªn 3* quy vá» 5*
        "6 sao": " 5star ",
        "6 star": " 5star ",
        "5star": " 5star ",
        "5 sao": " 5star ",
        "5sao": " 5star ",
        "starstarstarstarstar": " 5star ",
        "1 sao": " 1star ",
        "1sao": " 1star ",
        "2 sao": " 1star ",
        "2sao": " 1star ",
        "2 starstar": " 1star ",
        "1star": " 1star ",
        "0 sao": " 1star ",
        "0star": " 1star ",
    }

    for k, v in replace_list.items():
        text = text.replace(k, v)

    # chuyen punctuation thÃ nh space
    translator = str.maketrans(
        string.punctuation, " " * len(string.punctuation))
    text = text.translate(translator)

    text = ViTokenizer.tokenize(text)
    texts = text.split()
    # texts = [txt for txt in texts if txt not in stw_list]
    len_text = len(texts)

    # texts = [t.replace("_", " ") for t in texts]
    for i in range(len_text):
        cp_text = texts[i]
        if (
            cp_text in not_list
        ):  # Xá»­ lÃ½ váº¥n Ä‘á» phá»§ Ä‘á»‹nh (VD: Ã¡o nÃ y cháº³ng Ä‘áº¹p--> Ã¡o nÃ y notpos)
            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1

            for j in range(numb_word):
                if texts[i + j + 1] in pos_list:
                    texts[i] = "notpos"
                    texts[i + j + 1] = ""

                if texts[i + j + 1] in neg_list:
                    texts[i] = "notneg"
                    texts[i + j + 1] = ""
        # ThÃªm feature cho nhá»¯ng sentiment words (Ã¡o nÃ y Ä‘áº¹p--> Ã¡o nÃ y Ä‘áº¹p positive)
        else:
            if cp_text in pos_list:
                texts.append("positive")
            elif cp_text in neg_list:
                texts.append("negative")

    text = " ".join(texts)

    # remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a thÃ£i
    text = text.replace('"', " ").replace("ï¸", "").replace(
        "ğŸ»", "").replace(")", "").replace("\n", " ")
    text = text.strip()
    return text


def preprocessing_2(text):
    # Remove cÃ¡c kÃ½ tá»± kÃ©o dÃ i: vd: Ä‘áº¹ppppppp
    text = re.sub(
        r"([A-Z])\1+", lambda m: m.group(1).upper(), text, flags=re.IGNORECASE
    )

    # Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng
    text = text.lower()

    # Chuáº©n hÃ³a tiáº¿ng Viá»‡t, xá»­ lÃ½ emoj, chuáº©n hÃ³a tiáº¿ng Anh, thuáº­t ngá»¯
    replace_list = {
        "Ã²a": "oÃ ",
        "Ã³a": "oÃ¡",
        "á»a": "oáº£",
        "Ãµa": "oÃ£",
        "á»a": "oáº¡",
        "Ã²e": "oÃ¨",
        "Ã³e": "oÃ©",
        "á»e": "oáº»",
        "Ãµe": "oáº½",
        "á»e": "oáº¹",
        "Ã¹y": "uá»³",
        "Ãºy": "uÃ½",
        "á»§y": "uá»·",
        "Å©y": "uá»¹",
        "á»¥y": "uá»µ",
        "uáº£": "á»§a",
        "aÌ‰": "áº£",
        "Ã´Ì": "á»‘",
        "uÂ´": "á»‘",
        "Ã´Ìƒ": "á»—",
        "Ã´Ì€": "á»“",
        "Ã´Ì‰": "á»•",
        "Ã¢Ì": "áº¥",
        "Ã¢Ìƒ": "áº«",
        "Ã¢Ì‰": "áº©",
        "Ã¢Ì€": "áº§",
        "oÌ‰": "á»",
        "ÃªÌ€": "á»",
        "ÃªÌƒ": "á»…",
        "ÄƒÌ": "áº¯",
        "uÌ‰": "á»§",
        "ÃªÌ": "áº¿",
        "Æ¡Ì‰": "á»Ÿ",
        "iÌ‰": "á»‰",
        "eÌ‰": "áº»",
        "Ã k": " Ã  ",
        "aË‹": "Ã ",
        "iË‹": "Ã¬",
        "ÄƒÂ´": "áº¯",
        "Æ°Ì‰": "á»­",
        "eËœ": "áº½",
        "yËœ": "á»¹",
        "aÂ´": "Ã¡",
        # Quy cÃ¡c icon vá» 2 loáº¡i emoj: TÃ­ch cá»±c hoáº·c tiÃªu cá»±c
        "ğŸ‘¹": "negative",
        "ğŸ‘»": "positive",
        "ğŸ’ƒ": "positive",
        "ğŸ¤™": " positive ",
        "ğŸ‘": " positive ",
        "ğŸ’„": "positive",
        "ğŸ’": "positive",
        "ğŸ’©": "positive",
        "ğŸ˜•": "negative",
        "ğŸ˜±": "negative",
        "ğŸ˜¸": "positive",
        "ğŸ˜¾": "negative",
        "ğŸš«": "negative",
        "ğŸ¤¬": "negative",
        "ğŸ§š": "positive",
        "ğŸ§¡": "positive",
        "ğŸ¶": " positive ",
        "ğŸ‘": " negative ",
        "ğŸ˜£": " negative ",
        "âœ¨": " positive ",
        "â£": " positive ",
        "â˜€": " positive ",
        "â™¥": " positive ",
        "ğŸ¤©": " positive ",
        "like": " positive ",
        "ğŸ’Œ": " positive ",
        "ğŸ¤£": " positive ",
        "ğŸ–¤": " positive ",
        "ğŸ¤¤": " positive ",
        ":(": " negative ",
        "ğŸ˜¢": " negative ",
        "â¤": " positive ",
        "ğŸ˜": " positive ",
        "ğŸ˜˜": " positive ",
        "ğŸ˜ª": " negative ",
        "ğŸ˜Š": " positive ",
        "?": " ? ",
        "ğŸ˜": " positive ",
        "ğŸ’–": " positive ",
        "ğŸ˜Ÿ": " negative ",
        "ğŸ˜­": " negative ",
        "ğŸ’¯": " positive ",
        "ğŸ’—": " positive ",
        "â™¡": " positive ",
        "ğŸ’œ": " positive ",
        "ğŸ¤—": " positive ",
        "^^": " positive ",
        "ğŸ˜¨": " negative ",
        "â˜º": " positive ",
        "ğŸ’‹": " positive ",
        "ğŸ‘Œ": " positive ",
        "ğŸ˜–": " negative ",
        "ğŸ˜€": " positive ",
        ":((": " negative ",
        "ğŸ˜¡": " negative ",
        "ğŸ˜ ": " negative ",
        "ğŸ˜’": " negative ",
        "ğŸ™‚": " positive ",
        "ğŸ˜": " negative ",
        "ğŸ˜": " positive ",
        "ğŸ˜„": " positive ",
        "ğŸ˜™": " positive ",
        "ğŸ˜¤": " negative ",
        "ğŸ˜": " positive ",
        "ğŸ˜†": " positive ",
        "ğŸ’š": " positive ",
        "âœŒ": " positive ",
        "ğŸ’•": " positive ",
        "ğŸ˜": " negative ",
        "ğŸ˜“": " negative ",
        "ï¸ğŸ†—ï¸": " positive ",
        "ğŸ˜‰": " positive ",
        "ğŸ˜‚": " positive ",
        ":v": "  positive ",
        "=))": "  positive ",
        "ğŸ˜‹": " positive ",
        "ğŸ’“": " positive ",
        "ğŸ˜": " negative ",
        ":3": " positive ",
        "ğŸ˜«": " negative ",
        "ğŸ˜¥": " negative ",
        "ğŸ˜ƒ": " positive ",
        "ğŸ˜¬": " ğŸ˜¬ ",
        "ğŸ˜Œ": " ğŸ˜Œ ",
        "ğŸ’›": " positive ",
        "ğŸ¤": " positive ",
        "ğŸˆ": " positive ",
        "ğŸ˜—": " positive ",
        "ğŸ¤”": " negative ",
        "ğŸ˜‘": " negative ",
        "ğŸ”¥": " negative ",
        "ğŸ™": " negative ",
        "ğŸ†—": " positive ",
        "ğŸ˜»": " positive ",
        "ğŸ’™": " positive ",
        "ğŸ’Ÿ": " positive ",
        "ğŸ˜š": " positive ",
        "âŒ": " negative ",
        "ğŸ‘": " positive ",
        ";)": " positive ",
        "<3": " positive ",
        "ğŸŒ": " positive ",
        "ğŸŒ·": " positive ",
        "ğŸŒ¸": " positive ",
        "ğŸŒº": " positive ",
        "ğŸŒ¼": " positive ",
        "ğŸ“": " positive ",
        "ğŸ…": " positive ",
        "ğŸ¾": " positive ",
        "ğŸ‘‰": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’¥": " positive ",
        "ğŸ’ª": " positive ",
        "ğŸ’°": " positive ",
        "ğŸ˜‡": " positive ",
        "ğŸ˜›": " positive ",
        "ğŸ˜œ": " positive ",
        "ğŸ™ƒ": " positive ",
        "ğŸ¤‘": " positive ",
        "ğŸ¤ª": " positive ",
        "â˜¹": " negative ",
        "ğŸ’€": " negative ",
        "ğŸ˜”": " negative ",
        "ğŸ˜§": " negative ",
        "ğŸ˜©": " negative ",
        "ğŸ˜°": " negative ",
        "ğŸ˜³": " negative ",
        "ğŸ˜µ": " negative ",
        "ğŸ˜¶": " negative ",
        "ğŸ™": " negative ",
        # Chuáº©n hÃ³a 1 sá»‘ sentiment words/English words
        ":))": "  positive ",
        ":)": " positive ",
        "Ã´ kÃªi": " ok ",
        "okie": " ok ",
        " o kÃª ": " ok ",
        "okey": " ok ",
        "Ã´kÃª": " ok ",
        "oki": " ok ",
        " oke ": " ok ",
        " okay": " ok ",
        "okÃª": " ok ",
        " tks ": " cÃ¡m Æ¡n ",
        "thks": " cÃ¡m Æ¡n ",
        "thanks": " cÃ¡m Æ¡n ",
        "ths": " cÃ¡m Æ¡n ",
        "thank": " cÃ¡m Æ¡n ",
        "â­": "star ",
        "*": "star ",
        "ğŸŒŸ": "star ",
        "ğŸ‰": " positive ",
        "kg ": " khÃ´ng ",
        "not": " khÃ´ng ",
        " kg ": " khÃ´ng ",
        '"k ': " khÃ´ng ",
        " kh ": " khÃ´ng ",
        "kÃ´": " khÃ´ng ",
        "hok": " khÃ´ng ",
        " kp ": " khÃ´ng pháº£i ",
        " kÃ´ ": " khÃ´ng ",
        '"ko ': " khÃ´ng ",
        " ko ": " khÃ´ng ",
        " k ": " khÃ´ng ",
        "khong": " khÃ´ng ",
        " hok ": " khÃ´ng ",
        "he he": " positive ",
        "hehe": " positive ",
        "hihi": " positive ",
        "haha": " positive ",
        "hjhj": " positive ",
        " lol ": " negative ",
        " cc ": " negative ",
        "cute": " dá»… thÆ°Æ¡ng ",
        "huhu": " negative ",
        " vs ": " vá»›i ",
        "wa": " quÃ¡ ",
        "wÃ¡": " quÃ¡",
        "j": " gÃ¬ ",
        "â€œ": " ",
        " sz ": " cá»¡ ",
        "size": " cá»¡ ",
        " Ä‘x ": " Ä‘Æ°á»£c ",
        "dk": " Ä‘Æ°á»£c ",
        "dc": " Ä‘Æ°á»£c ",
        "Ä‘k": " Ä‘Æ°á»£c ",
        "Ä‘c": " Ä‘Æ°á»£c ",
        "authentic": " chuáº©n chÃ­nh hÃ£ng ",
        " aut ": " chuáº©n chÃ­nh hÃ£ng ",
        " auth ": " chuáº©n chÃ­nh hÃ£ng ",
        "thick": " positive ",
        "store": " cá»­a hÃ ng ",
        "shop": " cá»­a hÃ ng ",
        "sp": " sáº£n pháº©m ",
        "gud": " tá»‘t ",
        "god": " tá»‘t ",
        "wel done": " tá»‘t ",
        "good": " tá»‘t ",
        "gÃºt": " tá»‘t ",
        "sáº¥u": " xáº¥u ",
        "gut": " tá»‘t ",
        " tot ": " tá»‘t ",
        " nice ": " tá»‘t ",
        "perfect": "ráº¥t tá»‘t",
        "bt": " bÃ¬nh thÆ°á»ng ",
        "time": " thá»i gian ",
        "qÃ¡": " quÃ¡ ",
        " ship ": " giao hÃ ng ",
        " m ": " mÃ¬nh ",
        " mik ": " mÃ¬nh ",
        "ÃªÌ‰": "á»ƒ",
        "product": "sáº£n pháº©m",
        "quality": "cháº¥t lÆ°á»£ng",
        "chat": " cháº¥t ",
        "excelent": "hoÃ n háº£o",
        "bad": "tá»‡",
        "fresh": " tÆ°Æ¡i ",
        "sad": " tá»‡ ",
        "date": " háº¡n sá»­ dá»¥ng ",
        "hsd": " háº¡n sá»­ dá»¥ng ",
        "quickly": " nhanh ",
        "quick": " nhanh ",
        "fast": " nhanh ",
        "delivery": " giao hÃ ng ",
        " sÃ­p ": " giao hÃ ng ",
        "beautiful": " Ä‘áº¹p tuyá»‡t vá»i ",
        " tl ": " tráº£ lá»i ",
        " r ": " rá»“i ",
        " shopE ": " cá»­a hÃ ng ",
        " order ": " Ä‘áº·t hÃ ng ",
        "cháº¥t lg": " cháº¥t lÆ°á»£ng ",
        " sd ": " sá»­ dá»¥ng ",
        " dt ": " Ä‘iá»‡n thoáº¡i ",
        " nt ": " nháº¯n tin ",
        " tl ": " tráº£ lá»i ",
        " sÃ i ": " xÃ i ",
        "bjo": " bao giá» ",
        "thik": " thÃ­ch ",
        " sop ": " cá»­a hÃ ng ",
        " fb ": " facebook ",
        " face ": " facebook ",
        " very ": " ráº¥t ",
        "quáº£ ng ": " quáº£ng  ",
        "dep": " Ä‘áº¹p ",
        " xau ": " xáº¥u ",
        "delicious": " ngon ",
        "hÃ g": " hÃ ng ",
        "qá»§a": " quáº£ ",
        "iu": " yÃªu ",
        "fake": " giáº£ máº¡o ",
        "trl": "tráº£ lá»i",
        "><": " positive ",
        " por ": " tá»‡ ",
        " poor ": " tá»‡ ",
        "ib": " nháº¯n tin ",
        "rep": " tráº£ lá»i ",
        "fback": " feedback ",
        "fedback": " feedback ",
        # dÆ°á»›i 3* quy vá» 1*, trÃªn 3* quy vá» 5*
        "6 sao": " 5star ",
        "6 star": " 5star ",
        "5star": " 5star ",
        "5 sao": " 5star ",
        "5sao": " 5star ",
        "starstarstarstarstar": " 5star ",
        "1 sao": " 1star ",
        "1sao": " 1star ",
        "2 sao": " 1star ",
        "2sao": " 1star ",
        "2 starstar": " 1star ",
        "1star": " 1star ",
        "0 sao": " 1star ",
        "0star": " 1star ",
    }

    for k, v in replace_list.items():
        text = text.replace(k, v)

    # chuyen punctuation thÃ nh space
    translator = str.maketrans(
        string.punctuation, " " * len(string.punctuation))
    text = text.translate(translator)

    text = ViTokenizer.tokenize(text)

    # remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a thÃ£i
    text = text.replace('"', " ").replace("ï¸", "").replace(
        "ğŸ»", "").replace(")", "").replace("\n", " ")
    return text


dir_path = os.path.dirname(os.path.realpath(os.getcwd()))


def get_data(folder_path):
    # dirs = os.listdir(folder_path)
    X = []
    y = []
    for file_path in os.listdir(folder_path):
        if file_path.startswith("neg"):
            label = 0
        elif file_path.startswith("neu"):
            label = 2
        else:
            label = 1
        path = os.path.join(folder_path, file_path)
        with open(path, "r") as f:
            lines = f.read().split("\n")
            lines = [preprocessing(line) for line in lines]
            X.append(line for line in lines)
            y.append([label] * len(lines))

    return X, y


# train_path = os.path.join(dir_path, "data")
# print(os.listdir(train_path))
# X, y = get_data(train_path)
# # print(len(X))
# print(y)


def print_results(N, p, r):
    print("N\t" + str(N))
    print("P@{}\t{:.3f}".format(1, p))
    print("R@{}\t{:.3f}".format(1, r))


def test(model, test_path):
    data = {}
    with open(test_path, encoding="utf-8") as fp:
        for line in fp.readlines():
            line = line.strip()
            words = line.split()
            label = words[0]
            pred = model.predict(" ".join(words[1:]))[0][0]
            if label not in data:
                data[label] = {}
                data[label]["correct"] = 0
                data[label]["total"] = 0
            data[label]["total"] += 1
            if label == pred:
                data[label]["correct"] += 1
    summaries = {}
    for key in data:
        summaries[key] = round(data[key]["correct"] / data[key]["total"], 2)
    return summaries, data


def predict_results(model, sentence):
    res = model.predict(preprocessing(sentence))
    return res[0][0]


if __name__ == "__main__":
    current_dir = os.getcwd()
    data_path = os.path.join(current_dir, "data")
    train_data = "../data_preprocessed/train.txt"
    valid_data = "../data_preprocessed/test.txt"
    model = train_supervised(
        input=train_data,
        epoch=150,
        lr=0.05,
        wordNgrams=2,
        verbose=2,
        loss="softmax",
        label="__lb__",
    )
    print_results(*model.test(valid_data))
    summaries, details = test(model, valid_data)
    print(summaries)
    print(details)
    model.save_model("model/ft.li.1701.bin")
    # model = load_model("model/ft.li.1701.bin")
    # with open(valid_data, "r") as f:
    #     lines = f.read().split("\n")
    #     lines = [str(model.predict((line))[0]).replace(
    #         "('", "").replace("',)", "") + " " + line for line in lines]
    # with open("test4.txt", "w") as wf:
    #     for line in lines:
    #         wf.write(line + "\n")
